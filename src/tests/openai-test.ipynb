{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c319349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/belhalkarimi/Desktop/Belhal/Tech/taitris/taitris-ai/src/tests\n",
      "Script Path: /Users/belhalkarimi/Desktop/Belhal/Tech/taitris/taitris-ai/src/tests\n",
      "Parent Directory being added to sys.path: /Users/belhalkarimi/Desktop/Belhal/Tech/taitris/taitris-ai/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/belhalkarimi/Desktop/Belhal/Tech/presti-BK/belenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Config loading done.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "script_path = os.path.abspath(__file__) if '__file__' in locals() else os.getcwd()\n",
    "print(\"Script Path:\", script_path)\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(script_path, '..'))\n",
    "print(\"Parent Directory being added to sys.path:\", parent_dir)\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import fire\n",
    "\n",
    "from taitriscore.memory.memory import Memory\n",
    "from taitriscore.logs import logger\n",
    "from taitriscore.roles import Planner\n",
    "from taitriscore.config import CONFIG\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb6000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29194f85",
   "metadata": {},
   "source": [
    "### Test on calling openai API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef0f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b017b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = CONFIG.openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4237bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"gpt-3.5-turbo\"\n",
    "def _cons_kwargs(messages):\n",
    "    kwargs = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 100,\n",
    "        \"n\": 1,\n",
    "        \"stop\": None,\n",
    "        \"temperature\": 0.3,\n",
    "    }\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1c51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd5ffac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "def _user_msg(msg):\n",
    "    return {\"role\": \"user\", \"content\": msg}\n",
    "\n",
    "def _assistant_msg(msg):\n",
    "    return {\"role\": \"assistant\", \"content\": msg}\n",
    "\n",
    "def _system_msg(msg):\n",
    "    return {\"role\": \"system\", \"content\": msg}\n",
    "\n",
    "def _system_msgs(msgs):\n",
    "    return [_system_msg(msg) for msg in msgs]\n",
    "\n",
    "def _default_system_msg():\n",
    "    return _system_msg(system_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e789df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke for you:\n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two tired!\n"
     ]
    }
   ],
   "source": [
    "prompt = 'tell me a joke'\n",
    "messages = [_default_system_msg(), _user_msg(prompt)]\n",
    "res = llm.ChatCompletion.create(**_cons_kwargs(messages))\n",
    "\n",
    "# Print the response\n",
    "print(res['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516fd276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b956e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab07c0b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
